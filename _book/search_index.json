[
["index.html", "Introduction to Bayesian structrual equation modelling Chapter 1 Prerequisites", " Introduction to Bayesian structrual equation modelling Will Hardy 2020-05-23 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. "],
["introduction-to-structural-equation-modelling.html", "Chapter 2 Introduction to structural equation modelling 2.1 Specification 2.2 Identification 2.3 Estimation 2.4 Data collection and preparation 2.5 Respecification 2.6 Reporting results", " Chapter 2 Introduction to structural equation modelling What is structural equation modelling (SEM)? SEM is a variety of methods that analyse covariance matrices1. combination of factor analysis and path modelling There are six basic steps for most SEM analyses: Specify the model. Evaluate model identification (if not identified then return to step 1). Select the measures (operationalise the constructs) and collect, prepare, and screen the data. Estimate the model. Evaluate model fit; if it is poor then respecify the model if doing so is justifiable (skip to step 5); otherwise retain no model (skip to step 6). Respecify the model, which is assumed to be identified (return to step 4). Report the results. 2.1 Specification Hypotheses are often expressed with graphical conceptual models. These provide a visual representation of theoretical variables of interest and expected relationships between them. Outcome variables in SEM are referred to as endogenous variables. All must have at least one cause in the model. Some of these causes are independent variables. Independent variables in SEM are known as exogenous variables. The causes of these are not represented in the model. Specification is the most important step. Results from subsequent steps assume that the model/the hypotheses are basically correct. Making a list of changes, that are justifiable according to theory or empirical results, at this stage can be useful for step five. 2.2 Identification Graphical conceptual models are useful but need to be translated into statistical models that can be analysed. Statistical models must respect certain rules/restrictions. One of these is identification. A model is identified if it is theoretically possible for the computer to derive a unique estimate of every model parameter. This is a property of the model, not of the data. A researcher may specify a model that is true to a particular theory, but is not identified. To analyse such a model in SEM requires it to be respecified, but this may result in a model that is akin to making an intentional specification error in relation to the theory. 2.3 Estimation A computer SEM too will be used to conduct the analysis (e.g., Mplus, lavaan in R, AMOS). Evaluate model fit. How well does the model fit the data? When a model is a poor fit to the data, consider if respecification of the model can be justified given relevant theory and results of prior empirical studies. If/when a well fitting model is four, then interpret the parameter estimates. Consider equivalent or near equivalent models. An equivalent or near equivalent model may explain the data just as well as the researcher’s preferred model, but with a contradictory pattern of causal effects among some of the variables. Researchers should explain whey their preferred model should not be rejected in favour of equivalent ones. 2.4 Data collection and preparation 2.5 Respecification Researchers arrive at this step when initial model fit is poor. The list of justifiable modifications created earlier will be useful at this stage. Modifications should be guided by rational rather than statistical considerations. 2.6 Reporting results Many papers do not report results properly. There are guidelines available (???; ???, p 464). Covariance is…↩ "],
["introduction.html", "Chapter 3 Introduction 3.1 Priors 3.2 Estimating parameters 3.3 Regression exercise 3.4 References", " Chapter 3 Introduction What is it? Bayesian statistics assumes that all parameters (e.g., corelation coefficients) have a distribution. Frequentist statistics (a.k.a. classical or “normal” statistics) assumes that there is one try population parameter (e.g., there is one true coreelation coefficient). Posterior = (prior * likelihood) / (probability distribution). The probability distribution is only important with multiple hypotheses or datasets, so in many instances the formula can be simplified to: posterior = prior * likelihood or even more simply, posterior = what do we know before hand * what does the data say. Why would I use it? Why not? Just becasue it is not “normal” is not a reaosn to use it as long as you effectivley communicate your results. Bayesian statistics allows you to: Incoporate (un)certainty in your model. Update your knowledge. Some of the statistics are easier to interpret. There are no p-values. Credibility intervals (Bayesian) vs confidence intervals (Frequentist). A 95% confidence interval: in the long run, 95% of the confidence intervals will contain the true population value. A 95% credibility interval: there is 95% probability that the population value lies within the upper and lower bounds. Technical reasons (e.g., identifying complex models, improving convergence, more accurate parameter estimaes, non-normal data, missing data handling). Small samples. Bayes is not based on central limit theorem. It is also not a magical solution to small sample problems. 3.1 Priors Specific to populations - different populaitons will need different priors. Information about the parameter. Usually made up of three components: Shape (e.g., normal). Location (e.g., mean). Certainty (e.g., standard deviation). Take the scale of the data, so if you want to use standardised effects then you must use standardised data. There are lots of different names for types of priors, however they can be split into three main types: Uninformative/flat prior. Weakly informative. Strongly informative. Effects on the posterior: Priors need be specified before looking at the data as they will influence the results of any analyses. Strongly informative priors will result in a prior driven posterior where the results will be closer to the prior than the likelihood. Weakly informative priors will result in a data driven posterior where the reuslts will be close to the likelihood than the prior. Sample size is also important, the larger the sample, the larger the influce of the likelihood on the posterior. https://www.rensvandeschoot.com/fbi-the-app/ Where do priors come from? Prior research (e.g., meta analyses, individual studies, pilot studies). Expert elicitation. Software defaults if you don’t specify them yourself. Different software = different defaults (Erp, Mulder, and Oberski 2018). Prior data conflict. Can be because the prior chosen does not represent the sample populations (e.g., the prior is based on the general population and your sample population is the “healthy ageing population”). Can be of interest and the outcome of a study (e.g., the ability of teachers to predict students performance). Only likely to happen when you uses strongly informative priors. Documenting priors. You should explain which priors were chosen and why. This should be documented and proveided with any analyses. 3.2 Estimating parameters Gibbs sampler. Estimates the parameter assuming that the other parameters are known. Using a random start value, a parameter can be estimated. This parameter estimate is then passed to the next iteration of computation to replace the random start value. Simplifies computation. Chains represent starting values. Using multiple chains reduces the likelihood of accepting local convergence. A single chain may exhibit a stable mean and variance for a sufficent number of iterations to be accepted given a set of convergence criteria. However, that chain may, given enough time, change its mean. Two chains with different start values are less likely to display local convergence than one chain is, the probablity of three chains diplaying local convergence is smaller again, and so it goes on. Burn-in phase to remove the influence of starting values. More chains and/or more iterations allow for greater precision of estimates. Want stable means and variances within trace plots. If the model is correctly specified, it will eventually identify the target distribution. Convergence. Gibbs sampler must run for t iterations for the burn-in phase, where t is great enough to remove the influence of the start values. Convergence is when all chains reach the same target distribution (i.e., there would be no way to tell whcih chain the sample draw was from). To check that convergence is stable, it is normal to double the number of iterations to check that convergence remains. 9/10 times increasing the number of iterations will solve convergence issues. Including trace plots with manuscripts will allow others to (visually) assess convergence. It is also important to inspect posterior distributions - Do they look like you expected them to? Do they make sense? Autocorrelation is when an iteration is dependent on the last. One way to deal with auto correlation is through thinning where you only retain the nth sample. However, this does not acutally change the estimate and some would argue that it is unnecessary if the trace plots exhibit stable means and variances. Thinning doesn’t get rid of autocorrelation, it hides it. If using thinning, you require more iterations to recover precision. There are several ways to assess convergence (Kaplan and Depaoli 2012): Inspecting trace plots for stability and good mixing. Potential Scale Reduction Factor (PSR; Gelman and Rubin 1992). Different cut-off criteria, usually &gt;1.1 or &gt;1.05. In Mplus, with a single chain, PSR is defined using the third and fourth quarters of the chain. Kolmogorov-Smirnov (K-S) tests: a test of equality of the posterior parameter distributions across the different chains using draws from the chains. Geweke z-statistic: compares the first and last half of the post burn-in iterations. Significant test is evidence of local convergence. Sensitivity to priors. The effect of priors on the posterior distribution was described above. It is important to provided evidence of how robust the estimates are, or how sensitive they are to the prior specification. This is not an attempt to find the “best” prior (e.g., the one that provides a posterior that supports your hypotheses). And that is why it is important to specify your priors before you conduct any analyses. Analyses should be re-run with both more and less informative priors. Differences in parameter estimates should be reported both relative to the original estimate and in absolute values. This may be a sentence or short paragrah in the results, supported with supplementary information. Depaoli and van de Schoot (Depaoli and Schoot 2017) provide a checklist to help researchers avoid the naïve use of Bayesian statistics. 3.3 Regression exercise https://www.rensvandeschoot.com/tutorials/ &gt; WAMBS checklist &gt; exercise in programme of your choice. 3.4 References References "],
["introduction-1.html", "Chapter 4 Introduction 4.1 What does that mean? 4.2 Model fit 4.3 References", " Chapter 4 Introduction What is Bayesian structural equation modelling (BSEM)? In their paper introducing BSEM, Muthén and Asparouhov (2012, p 316) stated that: It is intended to produce an analysis that better reflects the researcher’s theories and prior beliefs. It does so by systematically using informative priors for parameters that should not be freely estimated according to the researcher’s theories and prior beliefs. In a frequentist analysis, such parameters are typically fixed at zero or are constrained to be equal to other parameters. In key applications, freeing these parameters would, in fact, produce a nonidentified model. The Bayesian analysis, however, identifies the model by substantively driven small-variance priors. It should be recognized that BSEM refers to the specific Bayesian approach proposed here of using informative, small-variance priors to reflect the researcher’s theories and prior beliefs. Typically, this would be combined with the use of noninformative priors for parameters that would not be restricted in a corresponding ML analysis. For example, major loadings would have a normal prior with a very large variance. The BSEM approach of using informative priors is applicable to any constrained parameter in an SEM. 4.1 What does that mean? Typical maximum-likelihood (ML) approaches to confirmatory factor analysis (CFA) only allow indicators to load on their intended factors and fix cross-loadings (i.e., loadings onto non-intended factors) and the correlation between residual-error terms to zero. This approach is said to be overly restrictive and often leads to rejection of models based on the Chi-square test of good fit (Marsh et al. 2009). Researchers therefore tend to rely on other fit-indices to justify accepting a model when the Chi-square test suggests that they should not, as they suggest it is overly sensitive to trivial misfit (Fong and Ho 2013). However, these indicies will also often reject the model, especially when there are a large number of indicators (Marsh, Hau, and Wen 2004). This can lead to researchers relaxing conventional criteria for model fit and/or modifying their model post-hoc to improve the fit, which can lead to the acceptance of a poor model or one with a fit that has been improved by chance based on iterative model respesifcaiton using modification indices (MacCallum, Roznowski, and Necowitz 1992). Whilst cross-loadings and correlated errors terms can be specified in ML-CFA, specifiying too many will often lead to an underidentified model (Asparouhov and Muthén 2009). Exploratory structural equation modelling is one alternative to tradition CFA approaches that less restrictive (i.e., it allows for cross-loadings), however it still does not allow for correlated residual error terms, nor does is it possible to specify how close to zero the cross-loadings shoudl be (Muthén and Asparouhov 2012). BSEM allows the specification of both cross-loadings and residual correlations that are approximately zero this is done by using small-variance (i.e., strongly informative) priors on these parameters. What approximatley zero means is defined by the user and may be informed by theory, however if these are large variance priors the model may be underidentified (Muthén and Asparouhov 2012). The user may or may not specify priors for the intended factor loadings, if they are not specified, the software default will be used. It is important to consider priors before analysing the data, especially in small samples, as there is growing evidence that the “naïve” use of priors can lead to biased estimates, sometimes worse than would be obtained through ML estimation (???). 4.2 Model fit Model fit can in BSEMs can be assessed in using a number of metrics: Number of free parameters Posterior Predictive p-value (PPp value) 95% Confidence Interval for the Difference Between the Observed and the Replicated Chi-Square Values Deviance Information Criterion (DIC) 4.3 References References "],
["running-bsem-analyses-in-amos.html", "Chapter 5 Running BSEM analyses in AMOS", " Chapter 5 Running BSEM analyses in AMOS Missing data Missing data can be dealt with prior to BSEM analysis in a variety of ways ranging from the simple (e.g., listwise deletion, mean imputation) to far more complicated mothods (e.g., multiple imputation). It is beyond the scope of this course to cover the various techniques and when to use them. By default, AMOS will do XX when there is missing data. Standardise variables Model specification Major loadings only Major loadings + minor cross-loadings Major loadings + minor cross-loadings + approximate zero covariance Additional output Indirect moments Run Prior specification Default for all variables in AMOS is an uninformative prior (uniform; - 1^38 to +1^38). Convergence: As far as I can tell, AMOS only uses a single MCMC chain. PSR SC for individual parameters Trace plots for each parameter Posterior First and last box creates polygons for the first and last third of the samples Fit: PPp Chi-square DIC Parameter estimates Sensitivity analyses More informative priors Less informative priors "],
["references-2.html", "References", " References "]
]
